{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ca035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "import search_space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c25092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': [309, 378, 264, 125, 368, 147, 39, 226],\n",
       " 'activation_fn': torch.nn.modules.activation.Tanh,\n",
       " 'dropout_rate': 0.5,\n",
       " 'optimizer_type': torch.optim.adamw.AdamW,\n",
       " 'learning_rate': 0.0015185491990797558,\n",
       " 'weight_decay': 0,\n",
       " 'momentum': None,\n",
       " 'batch_size': 128,\n",
       " 'use_skip_connections': True,\n",
       " 'initializer': 'kaiming_uniform',\n",
       " 'lr_scheduler': 'cosine',\n",
       " 'scheduler_params': {'T_max': 50},\n",
       " 'seed': 14}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_space = search_space.SearchSpace(100, 10)\n",
    "s_space.sample_architecture(seed=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76aed890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a432ceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': DynamicNN(\n",
       "   (network): Sequential(\n",
       "     (0): Linear(in_features=100, out_features=136, bias=True)\n",
       "     (1): ELU(alpha=1.0)\n",
       "     (2): Dropout(p=0.2, inplace=False)\n",
       "     (3): Linear(in_features=136, out_features=265, bias=True)\n",
       "     (4): ELU(alpha=1.0)\n",
       "     (5): Dropout(p=0.2, inplace=False)\n",
       "     (6): Linear(in_features=265, out_features=176, bias=True)\n",
       "     (7): ELU(alpha=1.0)\n",
       "     (8): Dropout(p=0.2, inplace=False)\n",
       "     (9): Linear(in_features=176, out_features=192, bias=True)\n",
       "     (10): ELU(alpha=1.0)\n",
       "     (11): Dropout(p=0.2, inplace=False)\n",
       "     (12): Linear(in_features=192, out_features=498, bias=True)\n",
       "     (13): ELU(alpha=1.0)\n",
       "     (14): Dropout(p=0.2, inplace=False)\n",
       "     (15): Linear(in_features=498, out_features=242, bias=True)\n",
       "     (16): ELU(alpha=1.0)\n",
       "     (17): Dropout(p=0.2, inplace=False)\n",
       "     (18): Linear(in_features=242, out_features=322, bias=True)\n",
       "     (19): ELU(alpha=1.0)\n",
       "     (20): Dropout(p=0.2, inplace=False)\n",
       "     (21): Linear(in_features=322, out_features=231, bias=True)\n",
       "     (22): ELU(alpha=1.0)\n",
       "     (23): Dropout(p=0.2, inplace=False)\n",
       "     (24): Linear(in_features=231, out_features=432, bias=True)\n",
       "     (25): ELU(alpha=1.0)\n",
       "     (26): Dropout(p=0.2, inplace=False)\n",
       "     (27): Linear(in_features=432, out_features=116, bias=True)\n",
       "     (28): ELU(alpha=1.0)\n",
       "     (29): Dropout(p=0.2, inplace=False)\n",
       "     (30): Linear(in_features=116, out_features=3, bias=True)\n",
       "     (31): ELU(alpha=1.0)\n",
       "     (32): Dropout(p=0.2, inplace=False)\n",
       "     (33): Linear(in_features=3, out_features=313, bias=True)\n",
       "     (34): ELU(alpha=1.0)\n",
       "     (35): Dropout(p=0.2, inplace=False)\n",
       "     (36): Linear(in_features=313, out_features=489, bias=True)\n",
       "     (37): ELU(alpha=1.0)\n",
       "     (38): Dropout(p=0.2, inplace=False)\n",
       "     (39): Linear(in_features=489, out_features=185, bias=True)\n",
       "     (40): ELU(alpha=1.0)\n",
       "     (41): Dropout(p=0.2, inplace=False)\n",
       "     (42): Linear(in_features=185, out_features=171, bias=True)\n",
       "     (43): ELU(alpha=1.0)\n",
       "     (44): Dropout(p=0.2, inplace=False)\n",
       "     (45): Linear(in_features=171, out_features=107, bias=True)\n",
       "     (46): ELU(alpha=1.0)\n",
       "     (47): Dropout(p=0.2, inplace=False)\n",
       "     (48): Linear(in_features=107, out_features=289, bias=True)\n",
       "     (49): ELU(alpha=1.0)\n",
       "     (50): Dropout(p=0.2, inplace=False)\n",
       "     (51): Linear(in_features=289, out_features=102, bias=True)\n",
       "     (52): ELU(alpha=1.0)\n",
       "     (53): Dropout(p=0.2, inplace=False)\n",
       "     (54): Linear(in_features=102, out_features=258, bias=True)\n",
       "     (55): ELU(alpha=1.0)\n",
       "     (56): Dropout(p=0.2, inplace=False)\n",
       "     (57): Linear(in_features=258, out_features=410, bias=True)\n",
       "     (58): ELU(alpha=1.0)\n",
       "     (59): Dropout(p=0.2, inplace=False)\n",
       "     (60): Linear(in_features=410, out_features=341, bias=True)\n",
       "     (61): ELU(alpha=1.0)\n",
       "     (62): Dropout(p=0.2, inplace=False)\n",
       "     (63): Linear(in_features=341, out_features=399, bias=True)\n",
       "     (64): ELU(alpha=1.0)\n",
       "     (65): Dropout(p=0.2, inplace=False)\n",
       "     (66): Linear(in_features=399, out_features=46, bias=True)\n",
       "     (67): ELU(alpha=1.0)\n",
       "     (68): Dropout(p=0.2, inplace=False)\n",
       "     (69): Linear(in_features=46, out_features=459, bias=True)\n",
       "     (70): ELU(alpha=1.0)\n",
       "     (71): Dropout(p=0.2, inplace=False)\n",
       "     (72): Linear(in_features=459, out_features=410, bias=True)\n",
       "     (73): ELU(alpha=1.0)\n",
       "     (74): Dropout(p=0.2, inplace=False)\n",
       "     (75): Linear(in_features=410, out_features=332, bias=True)\n",
       "     (76): ELU(alpha=1.0)\n",
       "     (77): Dropout(p=0.2, inplace=False)\n",
       "     (78): Linear(in_features=332, out_features=113, bias=True)\n",
       "     (79): ELU(alpha=1.0)\n",
       "     (80): Dropout(p=0.2, inplace=False)\n",
       "     (81): Linear(in_features=113, out_features=494, bias=True)\n",
       "     (82): ELU(alpha=1.0)\n",
       "     (83): Dropout(p=0.2, inplace=False)\n",
       "     (84): Linear(in_features=494, out_features=213, bias=True)\n",
       "     (85): ELU(alpha=1.0)\n",
       "     (86): Dropout(p=0.2, inplace=False)\n",
       "     (87): Linear(in_features=213, out_features=223, bias=True)\n",
       "     (88): ELU(alpha=1.0)\n",
       "     (89): Dropout(p=0.2, inplace=False)\n",
       "     (90): Linear(in_features=223, out_features=331, bias=True)\n",
       "     (91): ELU(alpha=1.0)\n",
       "     (92): Dropout(p=0.2, inplace=False)\n",
       "     (93): Linear(in_features=331, out_features=485, bias=True)\n",
       "     (94): ELU(alpha=1.0)\n",
       "     (95): Dropout(p=0.2, inplace=False)\n",
       "     (96): Linear(in_features=485, out_features=10, bias=True)\n",
       "   )\n",
       "   (criterion): CrossEntropyLoss()\n",
       " ),\n",
       " 'architecture': {'hidden_layers': [136,\n",
       "   265,\n",
       "   176,\n",
       "   192,\n",
       "   498,\n",
       "   242,\n",
       "   322,\n",
       "   231,\n",
       "   432,\n",
       "   116,\n",
       "   3,\n",
       "   313,\n",
       "   489,\n",
       "   185,\n",
       "   171,\n",
       "   107,\n",
       "   289,\n",
       "   102,\n",
       "   258,\n",
       "   410,\n",
       "   341,\n",
       "   399,\n",
       "   46,\n",
       "   459,\n",
       "   410,\n",
       "   332,\n",
       "   113,\n",
       "   494,\n",
       "   213,\n",
       "   223,\n",
       "   331,\n",
       "   485],\n",
       "  'activation_fn': torch.nn.modules.activation.ELU,\n",
       "  'dropout_rate': 0.2,\n",
       "  'optimizer_type': torch.optim.sgd.SGD,\n",
       "  'learning_rate': 0.08481300266417338,\n",
       "  'weight_decay': 0,\n",
       "  'momentum': 0.9,\n",
       "  'batch_size': 512,\n",
       "  'use_skip_connections': True,\n",
       "  'initializer': 'kaiming_normal',\n",
       "  'lr_scheduler': 'none',\n",
       "  'scheduler_params': {},\n",
       "  'seed': 12},\n",
       " 'batch_size': 512,\n",
       " 'n_instances': [],\n",
       " 'proportion_instances': [],\n",
       " 'effort': [],\n",
       " 'train_loss': [],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [],\n",
       " 'val_acc': [],\n",
       " 'forecasted_val_acc': [],\n",
       " 'score': 0.0,\n",
       " 'forecast_gain': 0.0,\n",
       " 'higher_than_baseline': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation = generations.Generation(s_space, 5, seed=3)\n",
    "generation\n",
    "generation.generation[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fdcf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with Dataset: vehicle\n",
      "Class column is not numeric. Applying LabelEncoder.\n",
      "Data loaded successfully! Format: tensor\n",
      "Training data shape: torch.Size([540, 18])\n",
      "y_training data shape: torch.Size([540])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': [147,\n",
       "  455,\n",
       "  401,\n",
       "  445,\n",
       "  327,\n",
       "  334,\n",
       "  435,\n",
       "  321,\n",
       "  96,\n",
       "  38,\n",
       "  423,\n",
       "  373,\n",
       "  17,\n",
       "  65,\n",
       "  343,\n",
       "  499,\n",
       "  496,\n",
       "  417],\n",
       " 'activation_fn': torch.nn.modules.activation.ReLU,\n",
       " 'dropout_rate': 0.2,\n",
       " 'optimizer_type': torch.optim.adamw.AdamW,\n",
       " 'learning_rate': 0.017149460348346638,\n",
       " 'weight_decay': 1e-06,\n",
       " 'momentum': None,\n",
       " 'batch_size': 128,\n",
       " 'use_skip_connections': False,\n",
       " 'initializer': 'xavier_normal',\n",
       " 'lr_scheduler': 'none',\n",
       " 'scheduler_params': {},\n",
       " 'seed': 13}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_preprocessing as dp\n",
    "\n",
    "DATA_ID = 54\n",
    "SEED = 13\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = dp.get_preprocessed_data(\n",
    "        dataset_id=DATA_ID, scaling=True, random_seed=13, return_as='tensor', task_type='classification')\n",
    "\n",
    "input_size, output_size  = dp.get_tensor_sizes(X_train, y_train)\n",
    "s_space = search_space.SearchSpace(input_size, output_size)\n",
    "s_space.sample_architecture(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27b79d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation = generations.Generation(s_space, 5, seed=13)\n",
    "# print(generation.generation[4])\n",
    "\n",
    "# generation.train_generation(X_train, y_train)\n",
    "# generation.validate_generation(X_val, y_val)\n",
    "# generation.train_generation(X_train, y_train)\n",
    "# generation.validate_generation(X_val, y_val)\n",
    "# generation.train_generation(X_train, y_train)\n",
    "# generation.validate_generation(X_val, y_val)\n",
    "# generation.train_generation(X_train, y_train)\n",
    "# generation.validate_generation(X_val, y_val)\n",
    "# print('Train_Acc:',generation.generation[4]['train_acc'])\n",
    "# print('Train_Acc:',generation.generation[4]['val_acc'])\n",
    "# print('Seed:', generation.generation[4]['architecture']['seed'])\n",
    "# # generation.generation[4]['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32ee8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting NaiveAutoML baseline...\n",
      "0.8296 0.6907 0.5 0.6819919999999999\n",
      "Getting NaiveAutoML baseline...\n",
      "0.8296 0.6740999999999999 0.4815 0.6567339999999998\n",
      "Getting NaiveAutoML baseline...\n",
      "0.8296 0.6879500000000001 0.4981 0.690774\n"
     ]
    }
   ],
   "source": [
    "import baseline_models as bm\n",
    "N_MODELS=50 \n",
    "\n",
    "print('Getting NaiveAutoML baseline...')\n",
    "naml_data = {}\n",
    "baseline_metric, time_budget, scoreboard = bm.get_models_and_baseline_metric(X_train, y_train, n_models=N_MODELS, random_state=SEED, strategy='mean') # Mean as baseline\n",
    "max_metric = bm.get_baseline_metric(scoreboard, strategy='best')\n",
    "median_metric = bm.get_baseline_metric(scoreboard, strategy='median')\n",
    "worst_metric = bm.get_baseline_metric(scoreboard, strategy='worst')\n",
    "\n",
    "print(max_metric, median_metric, worst_metric, baseline_metric)\n",
    "\n",
    "print('Getting NaiveAutoML baseline...')\n",
    "naml_data = {}\n",
    "baseline_metric, time_budget, scoreboard = bm.get_models_and_baseline_metric(X_train, y_train, n_models=N_MODELS, random_state=SEED, strategy='mean') # Mean as baseline\n",
    "max_metric = bm.get_baseline_metric(scoreboard, strategy='best')\n",
    "median_metric = bm.get_baseline_metric(scoreboard, strategy='median')\n",
    "worst_metric = bm.get_baseline_metric(scoreboard, strategy='worst')\n",
    "\n",
    "print(max_metric, median_metric, worst_metric, baseline_metric)\n",
    "\n",
    "print('Getting NaiveAutoML baseline...')\n",
    "naml_data = {}\n",
    "baseline_metric, time_budget, scoreboard = bm.get_models_and_baseline_metric(X_train, y_train, n_models=N_MODELS, random_state=SEED, strategy='mean') # Mean as baseline\n",
    "max_metric = bm.get_baseline_metric(scoreboard, strategy='best')\n",
    "median_metric = bm.get_baseline_metric(scoreboard, strategy='median')\n",
    "worst_metric = bm.get_baseline_metric(scoreboard, strategy='worst')\n",
    "\n",
    "print(max_metric, median_metric, worst_metric, baseline_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5456e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n",
      "                ('feature-pre-processor', PCA()),\n",
      "                ('learner', LinearDiscriminantAnalysis())])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "runtime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pipeline",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "default_hp",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "neg_log_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new_best",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "evaluation_report",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exception",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "learner_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "learner_hps",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "c3d42ec9-d2e3-4643-aa79-36a787548698",
       "rows": [
        [
         "0",
         "1756089620.703916",
         "0.1890275478363037",
         "Pipeline(steps=[('learner', ExtraTreesClassifier())])",
         "True",
         "-0.0781",
         "True",
         "{'neg_log_loss': [-0.04644928642478912, -0.01933072581125862, -0.10022378245143264, -0.14833773956289523, -0.07615311228364252]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.ExtraTreesClassifier",
         null
        ],
        [
         "1",
         "1756089620.9615262",
         "0.2566103935241699",
         "Pipeline(steps=[('learner', RandomForestClassifier())])",
         "True",
         "-0.0857",
         "False",
         "{'neg_log_loss': [-0.03238938371944043, -0.01986646100335996, -0.12542689575662452, -0.17344078363498905, -0.07713391053105395]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.RandomForestClassifier",
         null
        ],
        [
         "2",
         "1756089621.1795516",
         "0.21602511405944824",
         "Pipeline(steps=[('learner', HistGradientBoostingClassifier())])",
         "True",
         "-0.1386",
         "False",
         "{'neg_log_loss': [-0.09204743657846827, -0.0040480189223703784, -0.13734201553930445, -0.35732514958674355, -0.10235499047977976]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble.HistGradientBoostingClassifier",
         null
        ],
        [
         "3",
         "1756089621.1885524",
         "0.009000778198242188",
         "Pipeline(steps=[('learner', BernoulliNB())])",
         "True",
         "-1.0986",
         "False",
         "{'neg_log_loss': [-1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.BernoulliNB",
         null
        ],
        [
         "4",
         "1756089621.1960557",
         "0.006504058837890625",
         "Pipeline(steps=[('learner', DecisionTreeClassifier())])",
         "True",
         "-0.9612",
         "False",
         "{'neg_log_loss': [-2.220446049250313e-16, -2.220446049250313e-16, -1.2014551129705717, -2.4029102259411435, -1.201455112970572]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.tree._classes.DecisionTreeClassifier",
         null
        ],
        [
         "5",
         "1756089621.2050555",
         "0.007999897003173828",
         "Pipeline(steps=[('learner', GaussianNB())])",
         "True",
         "-0.0694",
         "True",
         "{'neg_log_loss': [-0.04100956309851174, -0.02114647303720298, -0.08364189789087763, -0.15268250306888745, -0.04868764377571978]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.GaussianNB",
         null
        ],
        [
         "6",
         "1756089621.2140555",
         "0.007999897003173828",
         "Pipeline(steps=[('learner', KNeighborsClassifier())])",
         "True",
         "-0.0693",
         "True",
         "{'neg_log_loss': [-0.08555168796095053, -0.03190375754648054, -0.045419261150086015, -0.14448645271464178, -0.03934187592362085]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neighbors._classification.KNeighborsClassifier",
         null
        ],
        [
         "7",
         "1756089621.2230554",
         "0.00799870491027832",
         "Pipeline(steps=[('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "True",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "8",
         "1756089621.2300553",
         "0.006999969482421875",
         "Pipeline(steps=[('learner', QuadraticDiscriminantAnalysis())])",
         "True",
         "-0.0393",
         "False",
         "{'neg_log_loss': [-0.02033882282053922, -0.006874530875041546, -0.07126184848119779, -0.088431765421948, -0.009473288916094506]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis",
         null
        ],
        [
         "9",
         "1756089622.396096",
         "1.165038824081421",
         "Pipeline(steps=[('learner', SVC(kernel='linear'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "10",
         "1756089623.5310192",
         "1.1329243183135986",
         "Pipeline(steps=[('learner', SVC())])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "11",
         "1756089624.67309",
         "1.1410679817199707",
         "Pipeline(steps=[('learner', SVC(kernel='poly'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "12",
         "1756089625.807839",
         "1.1337471008300781",
         "Pipeline(steps=[('learner', SVC(kernel='sigmoid'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "13",
         "1756089625.848343",
         "0.03950309753417969",
         "Pipeline(steps=[('learner', LogisticRegression())])",
         "True",
         "-0.125",
         "False",
         "{'neg_log_loss': [-0.10586739665897969, -0.11338099013615933, -0.12373262092477028, -0.16590115666682592, -0.11621763609916763]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.linear_model.LogisticRegression",
         null
        ],
        [
         "14",
         "1756089626.0654495",
         "0.21510648727416992",
         "Pipeline(steps=[('learner', MLPClassifier())])",
         "True",
         "-0.2457",
         "False",
         "{'neg_log_loss': [-0.23894488662172633, -0.2337053091565252, -0.2338554760358185, -0.26599994856419984, -0.2560883617468472]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neural_network._multilayer_perceptron.MLPClassifier",
         null
        ],
        [
         "15",
         "1756089626.0744514",
         "0.008001327514648438",
         "Pipeline(steps=[('learner', MultinomialNB())])",
         "True",
         "-0.5645",
         "False",
         "{'neg_log_loss': [-0.5609928817451079, -0.5667232724811946, -0.5727699718125812, -0.5611786179372092, -0.5607102005452893]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.MultinomialNB",
         null
        ],
        [
         "16",
         "1756089626.0854511",
         "0.009999752044677734",
         "Pipeline(steps=[('data-pre-processor', MinMaxScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463971, -0.010998712704285533, -0.077859434128104, -0.03382242862500615, -0.02039390400884155]}",
         "ok",
         null,
         "sklearn.preprocessing._data.MinMaxScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "17",
         "1756089626.094956",
         "0.00950479507446289",
         "Pipeline(steps=[('data-pre-processor', Normalizer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0798",
         "False",
         "{'neg_log_loss': [-0.07551739030452859, -0.006444051724226655, -0.09136355697541305, -0.1976785406383173, -0.027765861828409528]}",
         "ok",
         null,
         "sklearn.preprocessing._data.Normalizer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "18",
         "1756089626.1199567",
         "0.025000810623168945",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "True",
         "{'neg_log_loss': [-0.016706457025059872, -0.011699461478399701, -0.06809639651209903, -0.03712765102291668, -0.02157067009897631]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "19",
         "1756089626.1309557",
         "0.009999513626098633",
         "Pipeline(steps=[('data-pre-processor', QuantileTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0421",
         "False",
         "{'neg_log_loss': [-0.04812822664746923, -0.006905267454068744, -0.04761834785594303, -0.09538699530265109, -0.012567814172024964]}",
         "ok",
         null,
         "sklearn.preprocessing._data.QuantileTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "20",
         "1756089626.1404595",
         "0.009503841400146484",
         "Pipeline(steps=[('data-pre-processor', RobustScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463859, -0.010998712704285568, -0.07785943412810332, -0.033822428625006014, -0.020393904008841536]}",
         "ok",
         null,
         "sklearn.preprocessing._data.RobustScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "21",
         "1756089626.1494596",
         "0.007999897003173828",
         "Pipeline(steps=[('data-pre-processor', StandardScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463926, -0.010998712704285695, -0.07785943412810335, -0.033822428625006014, -0.02039390400884131]}",
         "ok",
         null,
         "sklearn.preprocessing._data.StandardScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "22",
         "1756089626.1574595",
         "0.007999897003173828",
         "Pipeline(steps=[('data-pre-processor', VarianceThreshold()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         "sklearn.feature_selection._variance_threshold.VarianceThreshold",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "23",
         "1756089626.2139637",
         "0.05550432205200195",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FastICA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.016706457025060024, -0.011699461478399694, -0.06809639651209888, -0.03712765102291687, -0.021570670098976515]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._fastica.FastICA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "24",
         "1756089626.2159638",
         "0.0009999275207519531",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FeatureAgglomeration()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.cluster._agglomerative.FeatureAgglomeration",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "25",
         "1756089626.2179637",
         "0.0009996891021728516",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', KernelPCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._kernel_pca.KernelPCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "26",
         "1756089626.2199638",
         "0.0009999275207519531",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', RBFSampler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.RBFSampler",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "27",
         "1756089626.2239664",
         "0.003002166748046875",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', Nystroem()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.Nystroem",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "28",
         "1756089626.2534695",
         "0.028504133224487305",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.01670645702506002, -0.011699461478399701, -0.0680963965120988, -0.03712765102291656, -0.021570670098976417]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "29",
         "1756089626.255469",
         "0.0009999275207519531",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PolynomialFeatures()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.preprocessing._polynomial.PolynomialFeatures",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "30",
         "1756089626.2574692",
         "0.0009975433349609375",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', SelectPercentile()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.SelectPercentile",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "31",
         "1756089626.259469",
         "0.0009999275207519531",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', GenericUnivariateSelect()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "32",
         "1756089626.2624714",
         "0.03150367736816406",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9315407511157, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=2.78638999e-05))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9315407511157, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 2.78638999e-05}"
        ],
        [
         "33",
         "1756089626.2959754",
         "0.033000946044921875",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5347814338139)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0126646916272))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822233, -0.05759198833682024, -0.25113600391805757, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5347814338139, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0126646916272}"
        ],
        [
         "34",
         "1756089626.3299763",
         "0.025506258010864258",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5481401374044)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0036752249145))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5481401374044, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0036752249145}"
        ],
        [
         "35",
         "1756089626.3574831",
         "0.025000333786010742",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5998732156961)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.7353222630493,\n                                            solver='lsqr',\n                                            tol=5.27237885e-05))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5998732156961, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 5.27237885e-05, 'shrinkage_factor': 0.7353222630493}"
        ],
        [
         "36",
         "1756089626.383484",
         "0.027507543563842773",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.8444919985298, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.1260935942274,\n                                            solver='lsqr',\n                                            tol=0.0431595164932))])",
         "False",
         "-0.1625",
         "False",
         "{'neg_log_loss': [-0.18132216027200726, -0.12465817930030362, -0.10582840692109965, -0.23817087669351553, -0.16277000214836437]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8444919985298, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0431595164932, 'shrinkage_factor': 0.1260935942274}"
        ],
        [
         "37",
         "1756089626.4119916",
         "0.02799820899963379",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9314218222815, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=3.94703141e-05))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090792, -0.05303457160817815, -0.057204277755926396, -0.27635881268623996, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9314218222815, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 3.94703141e-05}"
        ],
        [
         "38",
         "1756089626.4409895",
         "0.024505138397216797",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.5449313545702, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.5789509072356,\n                                            solver='lsqr',\n                                            tol=0.0109070384271))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5449313545702, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0109070384271, 'shrinkage_factor': 0.5789509072356}"
        ],
        [
         "39",
         "1756089626.4664948",
         "0.023999691009521484",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9203926577805)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.003908547625))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090795, -0.05303457160817799, -0.05720427775592637, -0.2763588126862397, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9203926577805, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.003908547625}"
        ],
        [
         "40",
         "1756089626.4924967",
         "0.031502485275268555",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.8492437652389)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0020799338063))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.15559869297906284, -0.062400215862080485, -0.058540803784691106, -0.24679677545863318, -0.12835700554456905]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8492437652389, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0020799338063}"
        ],
        [
         "41",
         "1756089626.5259988",
         "0.026506423950195312",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5777846958646)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0011141607722))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5777846958646, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0011141607722}"
        ],
        [
         "42",
         "1756089626.5535069",
         "0.027002573013305664",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7106243848796, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0025930933447))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7106243848796, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0025930933447}"
        ],
        [
         "43",
         "1756089626.5825093",
         "0.02550816535949707",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9849598305749)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.8492838728431,\n                                            solver='lsqr',\n                                            tol=1.12343093e-05))])",
         "False",
         "-0.1703",
         "False",
         "{'neg_log_loss': [-0.18948470761823766, -0.13784952211046358, -0.10429365784893271, -0.24169610450649873, -0.1783255918266479]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9849598305749, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 1.12343093e-05, 'shrinkage_factor': 0.8492838728431}"
        ],
        [
         "44",
         "1756089626.6100175",
         "0.02850961685180664",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5060848406574)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0269929377733))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5060848406574, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0269929377733}"
        ],
        [
         "45",
         "1756089626.639527",
         "0.025998353958129883",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.7988617766193)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=4.31876201e-05))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090795, -0.05303457160817799, -0.05720427775592637, -0.2763588126862397, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7988617766193, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 4.31876201e-05}"
        ],
        [
         "46",
         "1756089626.6675253",
         "0.031002521514892578",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9301265330778, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0005417524156))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9301265330778, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0005417524156}"
        ],
        [
         "47",
         "1756089626.700031",
         "0.025002717971801758",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.7806810411234)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.913149601673,\n                                            solver='lsqr',\n                                            tol=0.0037810987454))])",
         "False",
         "-0.2166",
         "False",
         "{'neg_log_loss': [-0.2454743535601243, -0.19474325102800227, -0.1289826871707455, -0.28777702097624913, -0.22616926209721047]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7806810411234, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0037810987454, 'shrinkage_factor': 0.913149601673}"
        ],
        [
         "48",
         "1756089626.7260337",
         "0.03250432014465332",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7643591910566, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=5.26391986e-05))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7643591910566, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 5.26391986e-05}"
        ],
        [
         "49",
         "1756089626.7605376",
         "0.02700066566467285",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.6101173809512, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.4275359802026,\n                                            solver='lsqr',\n                                            tol=0.0169374272868))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6101173809512, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0169374272868, 'shrinkage_factor': 0.4275359802026}"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 132
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>runtime</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>default_hp</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>new_best</th>\n",
       "      <th>evaluation_report</th>\n",
       "      <th>status</th>\n",
       "      <th>exception</th>\n",
       "      <th>data-pre-processor_class</th>\n",
       "      <th>data-pre-processor_hps</th>\n",
       "      <th>feature-pre-processor_class</th>\n",
       "      <th>feature-pre-processor_hps</th>\n",
       "      <th>learner_class</th>\n",
       "      <th>learner_hps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.189028</td>\n",
       "      <td>(ExtraTreesClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0781</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg_log_loss': [-0.04644928642478912, -0.019...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.256610</td>\n",
       "      <td>(RandomForestClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0857</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.03238938371944043, -0.019...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.216025</td>\n",
       "      <td>(HistGradientBoostingClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.1386</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.09204743657846827, -0.004...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble.HistGradientBoostingClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>(BernoulliNB())</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0986</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-1.09861228866811, -1.098612...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.naive_bayes.BernoulliNB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>(DecisionTreeClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-2.220446049250313e-16, -2.2...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.867424...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1368</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.16035567402090795, -0.053...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.8674244328158, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'None', 'tol': 0.0011374230463}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.962465...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.0932</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.0249245861243911, -0.0139...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.9624652108471, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 1.09248517e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.578283...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646313, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.5782839550113, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'manual', 'tol': 5.76102877e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.031506</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.502677...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646313, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.5026772837584, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 8.71810984e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.932887...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1898</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.21380164338428512, -0.164...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.9328879998965, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'manual', 'tol': 0.0006209151307...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   runtime  \\\n",
       "0    1.756090e+09  0.189028   \n",
       "1    1.756090e+09  0.256610   \n",
       "2    1.756090e+09  0.216025   \n",
       "3    1.756090e+09  0.009001   \n",
       "4    1.756090e+09  0.006504   \n",
       "..            ...       ...   \n",
       "127  1.756090e+09  0.027001   \n",
       "128  1.756090e+09  0.031505   \n",
       "129  1.756090e+09  0.028002   \n",
       "130  1.756090e+09  0.031506   \n",
       "131  1.756090e+09  0.024506   \n",
       "\n",
       "                                              pipeline  default_hp  \\\n",
       "0                             (ExtraTreesClassifier())        True   \n",
       "1                           (RandomForestClassifier())        True   \n",
       "2                   (HistGradientBoostingClassifier())        True   \n",
       "3                                      (BernoulliNB())        True   \n",
       "4                           (DecisionTreeClassifier())        True   \n",
       "..                                                 ...         ...   \n",
       "127  (PowerTransformer(), PCA(n_components=0.867424...       False   \n",
       "128  (PowerTransformer(), PCA(n_components=0.962465...       False   \n",
       "129  (PowerTransformer(), PCA(n_components=0.578283...       False   \n",
       "130  (PowerTransformer(), PCA(n_components=0.502677...       False   \n",
       "131  (PowerTransformer(), PCA(n_components=0.932887...       False   \n",
       "\n",
       "     neg_log_loss  new_best  \\\n",
       "0         -0.0781      True   \n",
       "1         -0.0857     False   \n",
       "2         -0.1386     False   \n",
       "3         -1.0986     False   \n",
       "4         -0.9612     False   \n",
       "..            ...       ...   \n",
       "127       -0.1368     False   \n",
       "128       -0.0932     False   \n",
       "129       -0.1310     False   \n",
       "130       -0.1310     False   \n",
       "131       -0.1898     False   \n",
       "\n",
       "                                     evaluation_report status exception  \\\n",
       "0    {'neg_log_loss': [-0.04644928642478912, -0.019...     ok      None   \n",
       "1    {'neg_log_loss': [-0.03238938371944043, -0.019...     ok      None   \n",
       "2    {'neg_log_loss': [-0.09204743657846827, -0.004...     ok      None   \n",
       "3    {'neg_log_loss': [-1.09861228866811, -1.098612...     ok      None   \n",
       "4    {'neg_log_loss': [-2.220446049250313e-16, -2.2...     ok      None   \n",
       "..                                                 ...    ...       ...   \n",
       "127  {'neg_log_loss': [-0.16035567402090795, -0.053...     ok      None   \n",
       "128  {'neg_log_loss': [-0.0249245861243911, -0.0139...     ok      None   \n",
       "129  {'neg_log_loss': [-0.15560454612646313, -0.062...     ok      None   \n",
       "130  {'neg_log_loss': [-0.15560454612646313, -0.062...     ok      None   \n",
       "131  {'neg_log_loss': [-0.21380164338428512, -0.164...     ok      None   \n",
       "\n",
       "                         data-pre-processor_class data-pre-processor_hps  \\\n",
       "0                                            None                   None   \n",
       "1                                            None                   None   \n",
       "2                                            None                   None   \n",
       "3                                            None                   None   \n",
       "4                                            None                   None   \n",
       "..                                            ...                    ...   \n",
       "127  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "128  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "129  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "130  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "131  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "\n",
       "        feature-pre-processor_class  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "..                              ...   \n",
       "127  sklearn.decomposition._pca.PCA   \n",
       "128  sklearn.decomposition._pca.PCA   \n",
       "129  sklearn.decomposition._pca.PCA   \n",
       "130  sklearn.decomposition._pca.PCA   \n",
       "131  sklearn.decomposition._pca.PCA   \n",
       "\n",
       "                             feature-pre-processor_hps  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2                                                 None   \n",
       "3                                                 None   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "127  {'keep_variance': 0.8674244328158, 'whiten': '...   \n",
       "128  {'keep_variance': 0.9624652108471, 'whiten': '...   \n",
       "129  {'keep_variance': 0.5782839550113, 'whiten': '...   \n",
       "130  {'keep_variance': 0.5026772837584, 'whiten': '...   \n",
       "131  {'keep_variance': 0.9328879998965, 'whiten': '...   \n",
       "\n",
       "                                         learner_class  \\\n",
       "0        sklearn.ensemble._forest.ExtraTreesClassifier   \n",
       "1      sklearn.ensemble._forest.RandomForestClassifier   \n",
       "2      sklearn.ensemble.HistGradientBoostingClassifier   \n",
       "3                      sklearn.naive_bayes.BernoulliNB   \n",
       "4         sklearn.tree._classes.DecisionTreeClassifier   \n",
       "..                                                 ...   \n",
       "127  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "128  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "129  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "130  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "131  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "\n",
       "                                           learner_hps  \n",
       "0                                                 None  \n",
       "1                                                 None  \n",
       "2                                                 None  \n",
       "3                                                 None  \n",
       "4                                                 None  \n",
       "..                                                 ...  \n",
       "127      {'shrinkage': 'None', 'tol': 0.0011374230463}  \n",
       "128       {'shrinkage': 'auto', 'tol': 1.09248517e-05}  \n",
       "129  {'shrinkage': 'manual', 'tol': 5.76102877e-05,...  \n",
       "130       {'shrinkage': 'auto', 'tol': 8.71810984e-05}  \n",
       "131  {'shrinkage': 'manual', 'tol': 0.0006209151307...  \n",
       "\n",
       "[132 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n",
      "                ('feature-pre-processor', PCA()),\n",
      "                ('learner', LinearDiscriminantAnalysis())])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "runtime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pipeline",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "default_hp",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "neg_log_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new_best",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "evaluation_report",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exception",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "learner_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "learner_hps",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "c849327c-7825-4f07-b9b4-89ffa0710af2",
       "rows": [
        [
         "0",
         "1756089629.4966652",
         "0.21753478050231934",
         "Pipeline(steps=[('learner', ExtraTreesClassifier())])",
         "True",
         "-0.0756",
         "True",
         "{'neg_log_loss': [-0.05987658680063783, -0.02359788938228025, -0.11190368892723518, -0.12606890819676872, -0.05636124074567717]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.ExtraTreesClassifier",
         null
        ],
        [
         "1",
         "1756089629.7572074",
         "0.2595396041870117",
         "Pipeline(steps=[('learner', RandomForestClassifier())])",
         "True",
         "-0.0814",
         "False",
         "{'neg_log_loss': [-0.028223388364678272, -0.015370365434709925, -0.08816916968815844, -0.1879156107462968, -0.08738656386550805]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.RandomForestClassifier",
         null
        ],
        [
         "2",
         "1756089630.0007975",
         "0.24158835411071777",
         "Pipeline(steps=[('learner', HistGradientBoostingClassifier())])",
         "True",
         "-0.1386",
         "False",
         "{'neg_log_loss': [-0.09204743657846827, -0.0040480189223703784, -0.13734201553930445, -0.35732514958674355, -0.10235499047977976]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble.HistGradientBoostingClassifier",
         null
        ],
        [
         "3",
         "1756089630.0097978",
         "0.00800013542175293",
         "Pipeline(steps=[('learner', BernoulliNB())])",
         "True",
         "-1.0986",
         "False",
         "{'neg_log_loss': [-1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.BernoulliNB",
         null
        ],
        [
         "4",
         "1756089630.0187976",
         "0.008999824523925781",
         "Pipeline(steps=[('learner', DecisionTreeClassifier())])",
         "True",
         "-0.9612",
         "False",
         "{'neg_log_loss': [-2.220446049250313e-16, -2.220446049250313e-16, -1.2014551129705717, -2.4029102259411435, -1.201455112970572]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.tree._classes.DecisionTreeClassifier",
         null
        ],
        [
         "5",
         "1756089630.0257998",
         "0.007002115249633789",
         "Pipeline(steps=[('learner', GaussianNB())])",
         "True",
         "-0.0694",
         "True",
         "{'neg_log_loss': [-0.04100956309851174, -0.02114647303720298, -0.08364189789087763, -0.15268250306888745, -0.04868764377571978]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.GaussianNB",
         null
        ],
        [
         "6",
         "1756089630.0357976",
         "0.008997917175292969",
         "Pipeline(steps=[('learner', KNeighborsClassifier())])",
         "True",
         "-0.0693",
         "True",
         "{'neg_log_loss': [-0.08555168796095053, -0.03190375754648054, -0.045419261150086015, -0.14448645271464178, -0.03934187592362085]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neighbors._classification.KNeighborsClassifier",
         null
        ],
        [
         "7",
         "1756089630.044302",
         "0.008504390716552734",
         "Pipeline(steps=[('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "True",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "8",
         "1756089630.0523036",
         "0.006999969482421875",
         "Pipeline(steps=[('learner', QuadraticDiscriminantAnalysis())])",
         "True",
         "-0.0393",
         "False",
         "{'neg_log_loss': [-0.02033882282053922, -0.006874530875041546, -0.07126184848119779, -0.088431765421948, -0.009473288916094506]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis",
         null
        ],
        [
         "9",
         "1756089631.256453",
         "1.2031497955322266",
         "Pipeline(steps=[('learner', SVC(kernel='linear'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "10",
         "1756089632.3883984",
         "1.1309430599212646",
         "Pipeline(steps=[('learner', SVC())])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "11",
         "1756089633.530105",
         "1.1397066116333008",
         "Pipeline(steps=[('learner', SVC(kernel='poly'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "12",
         "1756089634.6758628",
         "1.144756555557251",
         "Pipeline(steps=[('learner', SVC(kernel='sigmoid'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "13",
         "1756089634.7143707",
         "0.038507938385009766",
         "Pipeline(steps=[('learner', LogisticRegression())])",
         "True",
         "-0.125",
         "False",
         "{'neg_log_loss': [-0.10586739665897969, -0.11338099013615933, -0.12373262092477028, -0.16590115666682592, -0.11621763609916763]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.linear_model.LogisticRegression",
         null
        ],
        [
         "14",
         "1756089634.9329288",
         "0.21655774116516113",
         "Pipeline(steps=[('learner', MLPClassifier())])",
         "True",
         "-0.2267",
         "False",
         "{'neg_log_loss': [-0.17601062020923539, -0.25737323280185176, -0.2816203193057469, -0.2915634669298255, -0.12686677488789655]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neural_network._multilayer_perceptron.MLPClassifier",
         null
        ],
        [
         "15",
         "1756089634.9384327",
         "0.00550389289855957",
         "Pipeline(steps=[('learner', MultinomialNB())])",
         "True",
         "-0.5645",
         "False",
         "{'neg_log_loss': [-0.5609928817451079, -0.5667232724811946, -0.5727699718125812, -0.5611786179372092, -0.5607102005452893]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.MultinomialNB",
         null
        ],
        [
         "16",
         "1756089634.9489722",
         "0.009540319442749023",
         "Pipeline(steps=[('data-pre-processor', MinMaxScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463971, -0.010998712704285533, -0.077859434128104, -0.03382242862500615, -0.02039390400884155]}",
         "ok",
         null,
         "sklearn.preprocessing._data.MinMaxScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "17",
         "1756089634.9599724",
         "0.009999990463256836",
         "Pipeline(steps=[('data-pre-processor', Normalizer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0798",
         "False",
         "{'neg_log_loss': [-0.07551739030452859, -0.006444051724226655, -0.09136355697541305, -0.1976785406383173, -0.027765861828409528]}",
         "ok",
         null,
         "sklearn.preprocessing._data.Normalizer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "18",
         "1756089634.9789727",
         "0.01900029182434082",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "True",
         "{'neg_log_loss': [-0.016706457025059872, -0.011699461478399701, -0.06809639651209903, -0.03712765102291668, -0.02157067009897631]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "19",
         "1756089634.9899728",
         "0.009999513626098633",
         "Pipeline(steps=[('data-pre-processor', QuantileTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0421",
         "False",
         "{'neg_log_loss': [-0.04812822664746923, -0.006905267454068744, -0.04761834785594303, -0.09538699530265109, -0.012567814172024964]}",
         "ok",
         null,
         "sklearn.preprocessing._data.QuantileTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "20",
         "1756089634.9994771",
         "0.009504318237304688",
         "Pipeline(steps=[('data-pre-processor', RobustScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463859, -0.010998712704285568, -0.07785943412810332, -0.033822428625006014, -0.020393904008841536]}",
         "ok",
         null,
         "sklearn.preprocessing._data.RobustScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "21",
         "1756089635.007477",
         "0.006999492645263672",
         "Pipeline(steps=[('data-pre-processor', StandardScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463926, -0.010998712704285695, -0.07785943412810335, -0.033822428625006014, -0.02039390400884131]}",
         "ok",
         null,
         "sklearn.preprocessing._data.StandardScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "22",
         "1756089635.015477",
         "0.006999969482421875",
         "Pipeline(steps=[('data-pre-processor', VarianceThreshold()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         "sklearn.feature_selection._variance_threshold.VarianceThreshold",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "23",
         "1756089635.0609825",
         "0.04450559616088867",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FastICA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.01670645702506006, -0.011699461478399599, -0.0680963965120988, -0.03712765102291672, -0.021570670098976206]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._fastica.FastICA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "24",
         "1756089635.0629823",
         "0.0010001659393310547",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FeatureAgglomeration()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.cluster._agglomerative.FeatureAgglomeration",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "25",
         "1756089635.065983",
         "0.002001047134399414",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', KernelPCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._kernel_pca.KernelPCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "26",
         "1756089635.0679824",
         "0.0010004043579101562",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', RBFSampler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.RBFSampler",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "27",
         "1756089635.0699823",
         "0.0009989738464355469",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', Nystroem()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.Nystroem",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "28",
         "1756089635.0914886",
         "0.021506309509277344",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.01670645702506002, -0.011699461478399701, -0.0680963965120988, -0.03712765102291656, -0.021570670098976417]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "29",
         "1756089635.0924888",
         "0.0010001659393310547",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PolynomialFeatures()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.preprocessing._polynomial.PolynomialFeatures",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "30",
         "1756089635.0944889",
         "0.0009982585906982422",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', SelectPercentile()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.SelectPercentile",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "31",
         "1756089635.0964887",
         "0.0009989738464355469",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', GenericUnivariateSelect()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "32",
         "1756089635.0994885",
         "0.024711132049560547",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9695849865491, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.826718845471,\n                                            solver='lsqr',\n                                            tol=0.045420633295))])",
         "False",
         "-0.3087",
         "False",
         "{'neg_log_loss': [-0.2714735000827473, -0.32205609564287985, -0.3205649357268105, -0.2998697746751313, -0.32968230229246126]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9695849865491, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.045420633295, 'shrinkage_factor': 0.826718845471}"
        ],
        [
         "33",
         "1756089635.125202",
         "0.025502443313598633",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9371043704173)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.7620965025418,\n                                            solver='lsqr',\n                                            tol=9.99849715e-05))])",
         "False",
         "-0.1987",
         "False",
         "{'neg_log_loss': [-0.2240291289770894, -0.17478852782428825, -0.12039475202815023, -0.2681913354300883, -0.20611687108932072]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9371043704173, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 9.99849715e-05, 'shrinkage_factor': 0.7620965025418}"
        ],
        [
         "34",
         "1756089635.1527045",
         "0.02700018882751465",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.6951212750103, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.2972779700456,\n                                            solver='lsqr',\n                                            tol=7.16113485e-05))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6951212750103, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 7.16113485e-05, 'shrinkage_factor': 0.2972779700456}"
        ],
        [
         "35",
         "1756089635.1817048",
         "0.02650308609008789",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9889317380187)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.9016085798167,\n                                            solver='lsqr',\n                                            tol=9.84284936e-05))])",
         "False",
         "-0.1825",
         "False",
         "{'neg_log_loss': [-0.2061695065010458, -0.14885595765306833, -0.10834107979049287, -0.2576439269694685, -0.19147908026665983]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9889317380187, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 9.84284936e-05, 'shrinkage_factor': 0.9016085798167}"
        ],
        [
         "36",
         "1756089635.2092078",
         "0.023999929428100586",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.876484312996, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0236438193239))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090792, -0.05303457160817815, -0.057204277755926396, -0.27635881268623996, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.876484312996, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0236438193239}"
        ],
        [
         "37",
         "1756089635.234208",
         "0.026506900787353516",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.5471834392659, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0021935351632))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.2511360039180577, -0.12821957340435047]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5471834392659, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0021935351632}"
        ],
        [
         "38",
         "1756089635.261715",
         "0.028000354766845703",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.6414416949889)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0327321031149))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822233, -0.05759198833682024, -0.25113600391805757, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6414416949889, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0327321031149}"
        ],
        [
         "39",
         "1756089635.290715",
         "0.026505708694458008",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9733491097671, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.9500404583185,\n                                            solver='lsqr',\n                                            tol=0.0455113525235))])",
         "False",
         "-0.3343",
         "False",
         "{'neg_log_loss': [-0.2977156434681017, -0.3525778911664511, -0.34351825179323625, -0.3205609535917161, -0.35690415073114534]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9733491097671, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0455113525235, 'shrinkage_factor': 0.9500404583185}"
        ],
        [
         "40",
         "1756089635.3192198",
         "0.025506973266601562",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5973728043253)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.8331182993999,\n                                            solver='lsqr',\n                                            tol=0.0108610527996))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5973728043253, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0108610527996, 'shrinkage_factor': 0.8331182993999}"
        ],
        [
         "41",
         "1756089635.3467245",
         "0.029999732971191406",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.8289323939314, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=5.95813044e-05))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8289323939314, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 5.95813044e-05}"
        ],
        [
         "42",
         "1756089635.377725",
         "0.025503873825073242",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9845365056052, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.5744285312401,\n                                            solver='lsqr',\n                                            tol=3.29608692e-05))])",
         "False",
         "-0.2523",
         "False",
         "{'neg_log_loss': [-0.21349466430234534, -0.2533523292495176, -0.27008287594298586, -0.2543952340207569, -0.27017433183175904]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9845365056052, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 3.29608692e-05, 'shrinkage_factor': 0.5744285312401}"
        ],
        [
         "43",
         "1756089635.4042308",
         "0.023998022079467773",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.8649102734095)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.2167753999183,\n                                            solver='lsqr',\n                                            tol=0.0003005382104))])",
         "False",
         "-0.1421",
         "False",
         "{'neg_log_loss': [-0.16385005558908777, -0.09251624659608687, -0.07878065173869726, -0.2333698223504995, -0.14214920722046737]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8649102734095, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0003005382104, 'shrinkage_factor': 0.2167753999183}"
        ],
        [
         "44",
         "1756089635.430229",
         "0.024506330490112305",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7011342494613, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0006789772192))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7011342494613, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0006789772192}"
        ],
        [
         "45",
         "1756089635.456735",
         "0.029000043869018555",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.8574499664249)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.0390922488478,\n                                            solver='lsqr',\n                                            tol=0.0354414142756))])",
         "False",
         "-0.1351",
         "False",
         "{'neg_log_loss': [-0.1579843046167575, -0.060230522434299404, -0.061171411672355055, -0.26158408409348033, -0.13455036024491107]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8574499664249, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0354414142756, 'shrinkage_factor': 0.0390922488478}"
        ],
        [
         "46",
         "1756089635.4867349",
         "0.03250479698181152",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.8892823606033, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.1731273476988,\n                                            solver='lsqr',\n                                            tol=3.23090118e-05))])",
         "False",
         "-0.1776",
         "False",
         "{'neg_log_loss': [-0.19557682027214676, -0.14712428831610638, -0.12062079286200261, -0.24604599435429747, -0.17867788378268692]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8892823606033, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 3.23090118e-05, 'shrinkage_factor': 0.1731273476988}"
        ],
        [
         "47",
         "1756089635.5212395",
         "0.03050398826599121",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5453056385219)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.3345294837158,\n                                            solver='lsqr',\n                                            tol=0.0119629438589))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5453056385219, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0119629438589, 'shrinkage_factor': 0.3345294837158}"
        ],
        [
         "48",
         "1756089635.5527444",
         "0.02800130844116211",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.891952726076, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.004495783841))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090792, -0.05303457160817815, -0.057204277755926396, -0.27635881268623996, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.891952726076, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.004495783841}"
        ],
        [
         "49",
         "1756089635.5817442",
         "0.02850794792175293",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5186072922005)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.7607390157161,\n                                            solver='lsqr',\n                                            tol=0.002668242969))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5186072922005, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.002668242969, 'shrinkage_factor': 0.7607390157161}"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 132
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>runtime</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>default_hp</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>new_best</th>\n",
       "      <th>evaluation_report</th>\n",
       "      <th>status</th>\n",
       "      <th>exception</th>\n",
       "      <th>data-pre-processor_class</th>\n",
       "      <th>data-pre-processor_hps</th>\n",
       "      <th>feature-pre-processor_class</th>\n",
       "      <th>feature-pre-processor_hps</th>\n",
       "      <th>learner_class</th>\n",
       "      <th>learner_hps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.217535</td>\n",
       "      <td>(ExtraTreesClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0756</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg_log_loss': [-0.05987658680063783, -0.023...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.259540</td>\n",
       "      <td>(RandomForestClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0814</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.028223388364678272, -0.01...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.241588</td>\n",
       "      <td>(HistGradientBoostingClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.1386</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.09204743657846827, -0.004...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble.HistGradientBoostingClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>(BernoulliNB())</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0986</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-1.09861228866811, -1.098612...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.naive_bayes.BernoulliNB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>(DecisionTreeClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-2.220446049250313e-16, -2.2...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.028001</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.691176...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646304, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.6911761375248, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'manual', 'tol': 0.000112011702,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.861383...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1303</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15559869297906284, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.8613830342429, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 0.0012099816586}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.032002</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.555494...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646304, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.5554941999869, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'None', 'tol': 1.18204957e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.032506</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.609584...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646304, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.6095840316082, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'manual', 'tol': 2.07732913e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.033504</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.898659...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1303</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15559869297906284, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.8986590937672, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 5.87797214e-05}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   runtime  \\\n",
       "0    1.756090e+09  0.217535   \n",
       "1    1.756090e+09  0.259540   \n",
       "2    1.756090e+09  0.241588   \n",
       "3    1.756090e+09  0.008000   \n",
       "4    1.756090e+09  0.009000   \n",
       "..            ...       ...   \n",
       "127  1.756090e+09  0.028001   \n",
       "128  1.756090e+09  0.033046   \n",
       "129  1.756090e+09  0.032002   \n",
       "130  1.756090e+09  0.032506   \n",
       "131  1.756090e+09  0.033504   \n",
       "\n",
       "                                              pipeline  default_hp  \\\n",
       "0                             (ExtraTreesClassifier())        True   \n",
       "1                           (RandomForestClassifier())        True   \n",
       "2                   (HistGradientBoostingClassifier())        True   \n",
       "3                                      (BernoulliNB())        True   \n",
       "4                           (DecisionTreeClassifier())        True   \n",
       "..                                                 ...         ...   \n",
       "127  (PowerTransformer(), PCA(n_components=0.691176...       False   \n",
       "128  (PowerTransformer(), PCA(n_components=0.861383...       False   \n",
       "129  (PowerTransformer(), PCA(n_components=0.555494...       False   \n",
       "130  (PowerTransformer(), PCA(n_components=0.609584...       False   \n",
       "131  (PowerTransformer(), PCA(n_components=0.898659...       False   \n",
       "\n",
       "     neg_log_loss  new_best  \\\n",
       "0         -0.0756      True   \n",
       "1         -0.0814     False   \n",
       "2         -0.1386     False   \n",
       "3         -1.0986     False   \n",
       "4         -0.9612     False   \n",
       "..            ...       ...   \n",
       "127       -0.1310     False   \n",
       "128       -0.1303     False   \n",
       "129       -0.1310     False   \n",
       "130       -0.1310     False   \n",
       "131       -0.1303     False   \n",
       "\n",
       "                                     evaluation_report status exception  \\\n",
       "0    {'neg_log_loss': [-0.05987658680063783, -0.023...     ok      None   \n",
       "1    {'neg_log_loss': [-0.028223388364678272, -0.01...     ok      None   \n",
       "2    {'neg_log_loss': [-0.09204743657846827, -0.004...     ok      None   \n",
       "3    {'neg_log_loss': [-1.09861228866811, -1.098612...     ok      None   \n",
       "4    {'neg_log_loss': [-2.220446049250313e-16, -2.2...     ok      None   \n",
       "..                                                 ...    ...       ...   \n",
       "127  {'neg_log_loss': [-0.15560454612646304, -0.062...     ok      None   \n",
       "128  {'neg_log_loss': [-0.15559869297906284, -0.062...     ok      None   \n",
       "129  {'neg_log_loss': [-0.15560454612646304, -0.062...     ok      None   \n",
       "130  {'neg_log_loss': [-0.15560454612646304, -0.062...     ok      None   \n",
       "131  {'neg_log_loss': [-0.15559869297906284, -0.062...     ok      None   \n",
       "\n",
       "                         data-pre-processor_class data-pre-processor_hps  \\\n",
       "0                                            None                   None   \n",
       "1                                            None                   None   \n",
       "2                                            None                   None   \n",
       "3                                            None                   None   \n",
       "4                                            None                   None   \n",
       "..                                            ...                    ...   \n",
       "127  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "128  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "129  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "130  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "131  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "\n",
       "        feature-pre-processor_class  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "..                              ...   \n",
       "127  sklearn.decomposition._pca.PCA   \n",
       "128  sklearn.decomposition._pca.PCA   \n",
       "129  sklearn.decomposition._pca.PCA   \n",
       "130  sklearn.decomposition._pca.PCA   \n",
       "131  sklearn.decomposition._pca.PCA   \n",
       "\n",
       "                             feature-pre-processor_hps  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2                                                 None   \n",
       "3                                                 None   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "127  {'keep_variance': 0.6911761375248, 'whiten': '...   \n",
       "128  {'keep_variance': 0.8613830342429, 'whiten': '...   \n",
       "129  {'keep_variance': 0.5554941999869, 'whiten': '...   \n",
       "130  {'keep_variance': 0.6095840316082, 'whiten': '...   \n",
       "131  {'keep_variance': 0.8986590937672, 'whiten': '...   \n",
       "\n",
       "                                         learner_class  \\\n",
       "0        sklearn.ensemble._forest.ExtraTreesClassifier   \n",
       "1      sklearn.ensemble._forest.RandomForestClassifier   \n",
       "2      sklearn.ensemble.HistGradientBoostingClassifier   \n",
       "3                      sklearn.naive_bayes.BernoulliNB   \n",
       "4         sklearn.tree._classes.DecisionTreeClassifier   \n",
       "..                                                 ...   \n",
       "127  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "128  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "129  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "130  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "131  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "\n",
       "                                           learner_hps  \n",
       "0                                                 None  \n",
       "1                                                 None  \n",
       "2                                                 None  \n",
       "3                                                 None  \n",
       "4                                                 None  \n",
       "..                                                 ...  \n",
       "127  {'shrinkage': 'manual', 'tol': 0.000112011702,...  \n",
       "128      {'shrinkage': 'auto', 'tol': 0.0012099816586}  \n",
       "129       {'shrinkage': 'None', 'tol': 1.18204957e-05}  \n",
       "130  {'shrinkage': 'manual', 'tol': 2.07732913e-05,...  \n",
       "131       {'shrinkage': 'auto', 'tol': 5.87797214e-05}  \n",
       "\n",
       "[132 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n",
      "                ('feature-pre-processor', PCA()),\n",
      "                ('learner', LinearDiscriminantAnalysis())])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "runtime",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pipeline",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "default_hp",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "neg_log_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "new_best",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "evaluation_report",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "exception",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "data-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_class",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "feature-pre-processor_hps",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "learner_class",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "learner_hps",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "befb3b4e-abcd-4a1a-af9a-fe85ade1ee72",
       "rows": [
        [
         "0",
         "1756089638.3528526",
         "0.21303248405456543",
         "Pipeline(steps=[('learner', ExtraTreesClassifier())])",
         "True",
         "-0.0789",
         "True",
         "{'neg_log_loss': [-0.056046921122213565, -0.03001039532365554, -0.10713802281795932, -0.1312323515831406, -0.0699762724028901]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.ExtraTreesClassifier",
         null
        ],
        [
         "1",
         "1756089638.6133852",
         "0.2595326900482178",
         "Pipeline(steps=[('learner', RandomForestClassifier())])",
         "True",
         "-0.0843",
         "False",
         "{'neg_log_loss': [-0.028916359650784495, -0.017975261988704715, -0.1075285866367912, -0.17792177210611368, -0.08893474915148335]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble._forest.RandomForestClassifier",
         null
        ],
        [
         "2",
         "1756089638.8380795",
         "0.22369623184204102",
         "Pipeline(steps=[('learner', HistGradientBoostingClassifier())])",
         "True",
         "-0.1386",
         "False",
         "{'neg_log_loss': [-0.09204743657846827, -0.0040480189223703784, -0.13734201553930445, -0.35732514958674355, -0.10235499047977976]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.ensemble.HistGradientBoostingClassifier",
         null
        ],
        [
         "3",
         "1756089638.846585",
         "0.008505582809448242",
         "Pipeline(steps=[('learner', BernoulliNB())])",
         "True",
         "-1.0986",
         "False",
         "{'neg_log_loss': [-1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811, -1.09861228866811]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.BernoulliNB",
         null
        ],
        [
         "4",
         "1756089638.8545854",
         "0.006999015808105469",
         "Pipeline(steps=[('learner', DecisionTreeClassifier())])",
         "True",
         "-0.9612",
         "False",
         "{'neg_log_loss': [-2.220446049250313e-16, -2.220446049250313e-16, -1.2014551129705717, -1.201455112970572, -2.4029102259411435]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.tree._classes.DecisionTreeClassifier",
         null
        ],
        [
         "5",
         "1756089638.8615851",
         "0.0069997310638427734",
         "Pipeline(steps=[('learner', GaussianNB())])",
         "True",
         "-0.0694",
         "True",
         "{'neg_log_loss': [-0.04100956309851174, -0.02114647303720298, -0.08364189789087763, -0.15268250306888745, -0.04868764377571978]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.GaussianNB",
         null
        ],
        [
         "6",
         "1756089638.870587",
         "0.006999969482421875",
         "Pipeline(steps=[('learner', KNeighborsClassifier())])",
         "True",
         "-0.0693",
         "True",
         "{'neg_log_loss': [-0.08555168796095053, -0.03190375754648054, -0.045419261150086015, -0.14448645271464178, -0.03934187592362085]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neighbors._classification.KNeighborsClassifier",
         null
        ],
        [
         "7",
         "1756089638.8795989",
         "0.008011817932128906",
         "Pipeline(steps=[('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "True",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "8",
         "1756089638.8871627",
         "0.00756382942199707",
         "Pipeline(steps=[('learner', QuadraticDiscriminantAnalysis())])",
         "True",
         "-0.0393",
         "False",
         "{'neg_log_loss': [-0.02033882282053922, -0.006874530875041546, -0.07126184848119779, -0.088431765421948, -0.009473288916094506]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis",
         null
        ],
        [
         "9",
         "1756089640.0535893",
         "1.1654267311096191",
         "Pipeline(steps=[('learner', SVC(kernel='linear'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "10",
         "1756089641.1763458",
         "1.1217567920684814",
         "Pipeline(steps=[('learner', SVC())])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "11",
         "1756089642.311576",
         "1.1332287788391113",
         "Pipeline(steps=[('learner', SVC(kernel='poly'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "12",
         "1756089643.4312499",
         "1.1186749935150146",
         "Pipeline(steps=[('learner', SVC(kernel='sigmoid'))])",
         "True",
         null,
         "False",
         null,
         "exception",
         "AttributeError: Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\limiters\\limiter.py\", line 143, in __call__\n    result = self.func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 117, in __call__\n    scores = self.evaluate_splits(\n             ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 166, in evaluate_splits\n    split_results = self.evaluate_split(\n                    ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\evaluators.py\", line 214, in evaluate_split\n    out[scoring[\"name\"]] = scorer(pl_copy, X_test, y_test)\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 279, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 370, in _score\n    response_method = _check_response_method(estimator, self._response_method)\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2145, in _check_response_method\n    raise AttributeError(\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\naiveautoml\\commons.py\", line 164, in evaluate\n    scores, evaluation_report = limited_evaluation(\n                                ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 525, in __call__\n    return self._handle_return(result=result, err=err, tb=tb)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\user\\anaconda3\\envs\\AutoML\\Lib\\site-packages\\pynisher\\pynisher.py\", line 635, in _handle_return\n    raise err from err.__class__(tb)\nAttributeError: Pipeline has none of the following attributes: predict_proba.\n",
         null,
         null,
         null,
         null,
         "sklearn.svm._classes.SVC",
         null
        ],
        [
         "13",
         "1756089643.4657555",
         "0.03350567817687988",
         "Pipeline(steps=[('learner', LogisticRegression())])",
         "True",
         "-0.125",
         "False",
         "{'neg_log_loss': [-0.10586739665897969, -0.11338099013615933, -0.12373262092477028, -0.16590115666682592, -0.11621763609916763]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.linear_model.LogisticRegression",
         null
        ],
        [
         "14",
         "1756089643.6952858",
         "0.22752881050109863",
         "Pipeline(steps=[('learner', MLPClassifier())])",
         "True",
         "-0.2122",
         "False",
         "{'neg_log_loss': [-0.17132070152888204, -0.15280055270895188, -0.2740706708479333, -0.26234912501152247, -0.20032628729645502]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.neural_network._multilayer_perceptron.MLPClassifier",
         null
        ],
        [
         "15",
         "1756089643.7012863",
         "0.006000518798828125",
         "Pipeline(steps=[('learner', MultinomialNB())])",
         "True",
         "-0.5645",
         "False",
         "{'neg_log_loss': [-0.5609928817451079, -0.5667232724811946, -0.5727699718125812, -0.5611786179372092, -0.5607102005452893]}",
         "ok",
         null,
         null,
         null,
         null,
         null,
         "sklearn.naive_bayes.MultinomialNB",
         null
        ],
        [
         "16",
         "1756089643.7102866",
         "0.009000301361083984",
         "Pipeline(steps=[('data-pre-processor', MinMaxScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463971, -0.010998712704285533, -0.077859434128104, -0.03382242862500615, -0.02039390400884155]}",
         "ok",
         null,
         "sklearn.preprocessing._data.MinMaxScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "17",
         "1756089643.7192862",
         "0.00899958610534668",
         "Pipeline(steps=[('data-pre-processor', Normalizer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0798",
         "False",
         "{'neg_log_loss': [-0.07551739030452859, -0.006444051724226655, -0.09136355697541305, -0.1976785406383173, -0.027765861828409528]}",
         "ok",
         null,
         "sklearn.preprocessing._data.Normalizer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "18",
         "1756089643.742285",
         "0.022998809814453125",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "True",
         "{'neg_log_loss': [-0.016706457025059872, -0.011699461478399701, -0.06809639651209903, -0.03712765102291668, -0.02157067009897631]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "19",
         "1756089643.7537892",
         "0.01050424575805664",
         "Pipeline(steps=[('data-pre-processor', QuantileTransformer()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0421",
         "False",
         "{'neg_log_loss': [-0.04812822664746923, -0.006905267454068744, -0.04761834785594303, -0.09538699530265109, -0.012567814172024964]}",
         "ok",
         null,
         "sklearn.preprocessing._data.QuantileTransformer",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "20",
         "1756089643.763789",
         "0.008999824523925781",
         "Pipeline(steps=[('data-pre-processor', RobustScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463859, -0.010998712704285568, -0.07785943412810332, -0.033822428625006014, -0.020393904008841536]}",
         "ok",
         null,
         "sklearn.preprocessing._data.RobustScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "21",
         "1756089643.7727907",
         "0.009001731872558594",
         "Pipeline(steps=[('data-pre-processor', StandardScaler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463926, -0.010998712704285695, -0.07785943412810335, -0.033822428625006014, -0.02039390400884131]}",
         "ok",
         null,
         "sklearn.preprocessing._data.StandardScaler",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "22",
         "1756089643.783791",
         "0.010000944137573242",
         "Pipeline(steps=[('data-pre-processor', VarianceThreshold()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.0316",
         "False",
         "{'neg_log_loss': [-0.014828303968463998, -0.01099871270428559, -0.0778594341281027, -0.03382242862500614, -0.02039390400884129]}",
         "ok",
         null,
         "sklearn.feature_selection._variance_threshold.VarianceThreshold",
         null,
         null,
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "23",
         "1756089643.8438041",
         "0.05901074409484863",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FastICA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.01670645702506005, -0.011699461478399675, -0.06809639651209891, -0.03712765102291663, -0.021570670098976407]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._fastica.FastICA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "24",
         "1756089643.8458064",
         "0.002002239227294922",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', FeatureAgglomeration()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.cluster._agglomerative.FeatureAgglomeration",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "25",
         "1756089643.8488052",
         "0.0019991397857666016",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', KernelPCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._kernel_pca.KernelPCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "26",
         "1756089643.8518052",
         "0.0019998550415039062",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', RBFSampler()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.RBFSampler",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "27",
         "1756089643.854805",
         "0.0019991397857666016",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', Nystroem()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.kernel_approximation.Nystroem",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "28",
         "1756089643.8778102",
         "0.023005247116088867",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         "-0.031",
         "False",
         "{'neg_log_loss': [-0.01670645702506002, -0.011699461478399701, -0.0680963965120988, -0.03712765102291656, -0.021570670098976417]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "29",
         "1756089643.8803213",
         "0.0010063648223876953",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PolynomialFeatures()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.preprocessing._polynomial.PolynomialFeatures",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "30",
         "1756089643.8823202",
         "0.0019989013671875",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', SelectPercentile()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.SelectPercentile",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "31",
         "1756089643.8833218",
         "0.001001596450805664",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', GenericUnivariateSelect()),\n                ('learner', LinearDiscriminantAnalysis())])",
         "True",
         null,
         "False",
         null,
         "avoided",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.feature_selection._univariate_selection.GenericUnivariateSelect",
         null,
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         null
        ],
        [
         "32",
         "1756089643.885321",
         "0.02804708480834961",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9385749907633, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0210188521323))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9385749907633, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0210188521323}"
        ],
        [
         "33",
         "1756089643.914368",
         "0.025015592575073242",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.5677727817583)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=2.99472459e-05))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822233, -0.05759198833682024, -0.25113600391805757, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5677727817583, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 2.99472459e-05}"
        ],
        [
         "34",
         "1756089643.9409199",
         "0.026002883911132812",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.6416001114065, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=1.10023184e-05))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.2511360039180577, -0.12821957340435047]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6416001114065, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 1.10023184e-05}"
        ],
        [
         "35",
         "1756089643.9679227",
         "0.027999401092529297",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.6838433379979, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=2.13206478e-05))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6838433379979, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 2.13206478e-05}"
        ],
        [
         "36",
         "1756089643.996922",
         "0.0245058536529541",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9889414382504)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0591157370501))])",
         "False",
         "-0.0336",
         "False",
         "{'neg_log_loss': [-0.017346666446779783, -0.006240253592512142, -0.05916356490122157, -0.051652167244752606, -0.0334646017721141]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9889414382504, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0591157370501}"
        ],
        [
         "37",
         "1756089644.0234287",
         "0.031503915786743164",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7423570381353, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.018585270261,\n                                            solver='lsqr',\n                                            tol=0.0001356961662))])",
         "False",
         "-0.1358",
         "False",
         "{'neg_log_loss': [-0.15809092595609456, -0.0642157836982029, -0.06483294940675415, -0.2564379858051911, -0.13525410124156173]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7423570381353, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0001356961662, 'shrinkage_factor': 0.018585270261}"
        ],
        [
         "38",
         "1756089644.0569327",
         "0.02900242805480957",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7642655804726, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=6.49624056e-05))])",
         "False",
         "-0.1368",
         "False",
         "{'neg_log_loss': [-0.16035567402090792, -0.05303457160817815, -0.057204277755926396, -0.27635881268623996, -0.13698760829630782]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7642655804726, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 6.49624056e-05}"
        ],
        [
         "39",
         "1756089644.0869343",
         "0.030505657196044922",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9842584110267, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0003006371282))])",
         "False",
         "-0.0336",
         "False",
         "{'neg_log_loss': [-0.017346666446779967, -0.006240253592512096, -0.05916356490122169, -0.05165216724475271, -0.03346460177211452]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9842584110267, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0003006371282}"
        ],
        [
         "40",
         "1756089644.11944",
         "0.03150224685668945",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.6142811314578, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.5587287420833,\n                                            solver='lsqr',\n                                            tol=0.0117256821884))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.6142811314578, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0117256821884, 'shrinkage_factor': 0.5587287420833}"
        ],
        [
         "41",
         "1756089644.1529446",
         "0.029999494552612305",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.7198265833625)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.2353772479156,\n                                            solver='lsqr',\n                                            tol=0.0120401149869))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646304, -0.06236990092822234, -0.05759198833682024, -0.2511360039180575, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7198265833625, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0120401149869, 'shrinkage_factor': 0.2353772479156}"
        ],
        [
         "42",
         "1756089644.183942",
         "0.029509544372558594",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9299110355541, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.9597643184612,\n                                            solver='lsqr',\n                                            tol=0.0047489962909))])",
         "False",
         "-0.3416",
         "False",
         "{'neg_log_loss': [-0.37685455385296746, -0.3528734253637799, -0.23117877461907382, -0.3952642395852312, -0.3519852103871443]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9299110355541, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0047489962909, 'shrinkage_factor': 0.9597643184612}"
        ],
        [
         "43",
         "1756089644.2144516",
         "0.025503158569335938",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.8393540848895, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.0896923322858,\n                                            solver='lsqr',\n                                            tol=0.0002504416991))])",
         "False",
         "-0.151",
         "False",
         "{'neg_log_loss': [-0.17068748174907214, -0.10547962760087319, -0.09296889471153745, -0.23528172418710264, -0.15064329405541113]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.8393540848895, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0002504416991, 'shrinkage_factor': 0.0896923322858}"
        ],
        [
         "44",
         "1756089644.2419546",
         "0.032051801681518555",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9774018414595, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage=0.2719776798815,\n                                            solver='lsqr',\n                                            tol=0.0261825735343))])",
         "False",
         "-0.1637",
         "False",
         "{'neg_log_loss': [-0.12615761344113366, -0.14493540786774597, -0.18895401060731318, -0.1782988828901284, -0.18034508185492754]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9774018414595, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('manual'), 'tol': 0.0261825735343, 'shrinkage_factor': 0.2719776798815}"
        ],
        [
         "45",
         "1756089644.2760048",
         "0.027506351470947266",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor', PCA(n_components=0.9917000036571)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0380432194541))])",
         "False",
         "-0.0422",
         "False",
         "{'neg_log_loss': [-0.0249245861243911, -0.013950321194741237, -0.052057648914083945, -0.0739532372566116, -0.04619475511516142]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9917000036571, 'whiten': np.str_('False')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0380432194541}"
        ],
        [
         "46",
         "1756089644.30451",
         "0.031000614166259766",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7107156204839, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0002570322295))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.2511360039180577, -0.12821957340435047]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7107156204839, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0002570322295}"
        ],
        [
         "47",
         "1756089644.3365104",
         "0.029512643814086914",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.7116119800784, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0001295410224))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.2511360039180577, -0.12821957340435047]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.7116119800784, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0001295410224}"
        ],
        [
         "48",
         "1756089644.3680236",
         "0.024507522583007812",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.5528311425689, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(solver='lsqr',\n                                            tol=0.0043910690248))])",
         "False",
         "-0.131",
         "False",
         "{'neg_log_loss': [-0.15560454612646313, -0.06236990092822243, -0.057591988336820256, -0.25113600391805774, -0.12821957340435045]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.5528311425689, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('None'), 'tol': 0.0043910690248}"
        ],
        [
         "49",
         "1756089644.3935308",
         "0.029001951217651367",
         "Pipeline(steps=[('data-pre-processor', PowerTransformer()),\n                ('feature-pre-processor',\n                 PCA(n_components=0.9120568028854, whiten=True)),\n                ('learner',\n                 LinearDiscriminantAnalysis(shrinkage='auto', solver='lsqr',\n                                            tol=0.0010613087147))])",
         "False",
         "-0.1303",
         "False",
         "{'neg_log_loss': [-0.1555986929790629, -0.062400215862080555, -0.05854080378469121, -0.2467967754586333, -0.12835700554456908]}",
         "ok",
         null,
         "sklearn.preprocessing._data.PowerTransformer",
         null,
         "sklearn.decomposition._pca.PCA",
         "{'keep_variance': 0.9120568028854, 'whiten': np.str_('True')}",
         "sklearn.discriminant_analysis.LinearDiscriminantAnalysis",
         "{'shrinkage': np.str_('auto'), 'tol': 0.0010613087147}"
        ]
       ],
       "shape": {
        "columns": 15,
        "rows": 132
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>runtime</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>default_hp</th>\n",
       "      <th>neg_log_loss</th>\n",
       "      <th>new_best</th>\n",
       "      <th>evaluation_report</th>\n",
       "      <th>status</th>\n",
       "      <th>exception</th>\n",
       "      <th>data-pre-processor_class</th>\n",
       "      <th>data-pre-processor_hps</th>\n",
       "      <th>feature-pre-processor_class</th>\n",
       "      <th>feature-pre-processor_hps</th>\n",
       "      <th>learner_class</th>\n",
       "      <th>learner_hps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.213032</td>\n",
       "      <td>(ExtraTreesClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0789</td>\n",
       "      <td>True</td>\n",
       "      <td>{'neg_log_loss': [-0.056046921122213565, -0.03...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.259533</td>\n",
       "      <td>(RandomForestClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.0843</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.028916359650784495, -0.01...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.223696</td>\n",
       "      <td>(HistGradientBoostingClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.1386</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.09204743657846827, -0.004...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.ensemble.HistGradientBoostingClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.008506</td>\n",
       "      <td>(BernoulliNB())</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0986</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-1.09861228866811, -1.098612...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.naive_bayes.BernoulliNB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>(DecisionTreeClassifier())</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-2.220446049250313e-16, -2.2...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.565336...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1310</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.15560454612646304, -0.062...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.5653360171619, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'None', 'tol': 0.0540415388842}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.029508</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.751253...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1303</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.1555986929790629, -0.0624...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.7512530025653, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 0.01714504035}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.771184...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1368</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.16035567402090792, -0.053...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.7711847976783, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'None', 'tol': 1.33632543e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.036512</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.766217...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1303</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.1555986929790629, -0.0624...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.7662177405135, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'auto', 'tol': 1.16188222e-05}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.756090e+09</td>\n",
       "      <td>0.031128</td>\n",
       "      <td>(PowerTransformer(), PCA(n_components=0.878559...</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.1368</td>\n",
       "      <td>False</td>\n",
       "      <td>{'neg_log_loss': [-0.16035567402090792, -0.053...</td>\n",
       "      <td>ok</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.preprocessing._data.PowerTransformer</td>\n",
       "      <td>None</td>\n",
       "      <td>sklearn.decomposition._pca.PCA</td>\n",
       "      <td>{'keep_variance': 0.8785597023882, 'whiten': '...</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>{'shrinkage': 'None', 'tol': 0.0001395254291}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             time   runtime  \\\n",
       "0    1.756090e+09  0.213032   \n",
       "1    1.756090e+09  0.259533   \n",
       "2    1.756090e+09  0.223696   \n",
       "3    1.756090e+09  0.008506   \n",
       "4    1.756090e+09  0.006999   \n",
       "..            ...       ...   \n",
       "127  1.756090e+09  0.024504   \n",
       "128  1.756090e+09  0.029508   \n",
       "129  1.756090e+09  0.025000   \n",
       "130  1.756090e+09  0.036512   \n",
       "131  1.756090e+09  0.031128   \n",
       "\n",
       "                                              pipeline  default_hp  \\\n",
       "0                             (ExtraTreesClassifier())        True   \n",
       "1                           (RandomForestClassifier())        True   \n",
       "2                   (HistGradientBoostingClassifier())        True   \n",
       "3                                      (BernoulliNB())        True   \n",
       "4                           (DecisionTreeClassifier())        True   \n",
       "..                                                 ...         ...   \n",
       "127  (PowerTransformer(), PCA(n_components=0.565336...       False   \n",
       "128  (PowerTransformer(), PCA(n_components=0.751253...       False   \n",
       "129  (PowerTransformer(), PCA(n_components=0.771184...       False   \n",
       "130  (PowerTransformer(), PCA(n_components=0.766217...       False   \n",
       "131  (PowerTransformer(), PCA(n_components=0.878559...       False   \n",
       "\n",
       "     neg_log_loss  new_best  \\\n",
       "0         -0.0789      True   \n",
       "1         -0.0843     False   \n",
       "2         -0.1386     False   \n",
       "3         -1.0986     False   \n",
       "4         -0.9612     False   \n",
       "..            ...       ...   \n",
       "127       -0.1310     False   \n",
       "128       -0.1303     False   \n",
       "129       -0.1368     False   \n",
       "130       -0.1303     False   \n",
       "131       -0.1368     False   \n",
       "\n",
       "                                     evaluation_report status exception  \\\n",
       "0    {'neg_log_loss': [-0.056046921122213565, -0.03...     ok      None   \n",
       "1    {'neg_log_loss': [-0.028916359650784495, -0.01...     ok      None   \n",
       "2    {'neg_log_loss': [-0.09204743657846827, -0.004...     ok      None   \n",
       "3    {'neg_log_loss': [-1.09861228866811, -1.098612...     ok      None   \n",
       "4    {'neg_log_loss': [-2.220446049250313e-16, -2.2...     ok      None   \n",
       "..                                                 ...    ...       ...   \n",
       "127  {'neg_log_loss': [-0.15560454612646304, -0.062...     ok      None   \n",
       "128  {'neg_log_loss': [-0.1555986929790629, -0.0624...     ok      None   \n",
       "129  {'neg_log_loss': [-0.16035567402090792, -0.053...     ok      None   \n",
       "130  {'neg_log_loss': [-0.1555986929790629, -0.0624...     ok      None   \n",
       "131  {'neg_log_loss': [-0.16035567402090792, -0.053...     ok      None   \n",
       "\n",
       "                         data-pre-processor_class data-pre-processor_hps  \\\n",
       "0                                            None                   None   \n",
       "1                                            None                   None   \n",
       "2                                            None                   None   \n",
       "3                                            None                   None   \n",
       "4                                            None                   None   \n",
       "..                                            ...                    ...   \n",
       "127  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "128  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "129  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "130  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "131  sklearn.preprocessing._data.PowerTransformer                   None   \n",
       "\n",
       "        feature-pre-processor_class  \\\n",
       "0                              None   \n",
       "1                              None   \n",
       "2                              None   \n",
       "3                              None   \n",
       "4                              None   \n",
       "..                              ...   \n",
       "127  sklearn.decomposition._pca.PCA   \n",
       "128  sklearn.decomposition._pca.PCA   \n",
       "129  sklearn.decomposition._pca.PCA   \n",
       "130  sklearn.decomposition._pca.PCA   \n",
       "131  sklearn.decomposition._pca.PCA   \n",
       "\n",
       "                             feature-pre-processor_hps  \\\n",
       "0                                                 None   \n",
       "1                                                 None   \n",
       "2                                                 None   \n",
       "3                                                 None   \n",
       "4                                                 None   \n",
       "..                                                 ...   \n",
       "127  {'keep_variance': 0.5653360171619, 'whiten': '...   \n",
       "128  {'keep_variance': 0.7512530025653, 'whiten': '...   \n",
       "129  {'keep_variance': 0.7711847976783, 'whiten': '...   \n",
       "130  {'keep_variance': 0.7662177405135, 'whiten': '...   \n",
       "131  {'keep_variance': 0.8785597023882, 'whiten': '...   \n",
       "\n",
       "                                         learner_class  \\\n",
       "0        sklearn.ensemble._forest.ExtraTreesClassifier   \n",
       "1      sklearn.ensemble._forest.RandomForestClassifier   \n",
       "2      sklearn.ensemble.HistGradientBoostingClassifier   \n",
       "3                      sklearn.naive_bayes.BernoulliNB   \n",
       "4         sklearn.tree._classes.DecisionTreeClassifier   \n",
       "..                                                 ...   \n",
       "127  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "128  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "129  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "130  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "131  sklearn.discriminant_analysis.LinearDiscrimina...   \n",
       "\n",
       "                                       learner_hps  \n",
       "0                                             None  \n",
       "1                                             None  \n",
       "2                                             None  \n",
       "3                                             None  \n",
       "4                                             None  \n",
       "..                                             ...  \n",
       "127  {'shrinkage': 'None', 'tol': 0.0540415388842}  \n",
       "128    {'shrinkage': 'auto', 'tol': 0.01714504035}  \n",
       "129   {'shrinkage': 'None', 'tol': 1.33632543e-05}  \n",
       "130   {'shrinkage': 'auto', 'tol': 1.16188222e-05}  \n",
       "131  {'shrinkage': 'None', 'tol': 0.0001395254291}  \n",
       "\n",
       "[132 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import naiveautoml\n",
    "import sklearn.datasets\n",
    "naml = naiveautoml.NaiveAutoML(random_state=13)\n",
    "X, y = sklearn.datasets.load_iris(return_X_y=True)\n",
    "naml.fit(X, y)\n",
    "\n",
    "print(naml.chosen_model)\n",
    "display(naml.history)\n",
    "\n",
    "naml = naiveautoml.NaiveAutoML(random_state=13)\n",
    "naml.fit(X, y)\n",
    "\n",
    "print(naml.chosen_model)\n",
    "display(naml.history)\n",
    "\n",
    "naml = naiveautoml.NaiveAutoML(random_state=13)\n",
    "naml.fit(X, y)\n",
    "\n",
    "print(naml.chosen_model)\n",
    "display(naml.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
